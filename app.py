import os
import uuid
import logging
from flask import Flask, request, jsonify, session as flask_session
from flask_cors import CORS
import google.generativeai as genai

# â€”â€”â€”â€”â€” ConfiguraciÃ³n bÃ¡sica â€”â€”â€”â€”â€”
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.secret_key = os.getenv("SECRET_KEY", "dev_secret_key")

# â€”â€”â€”â€”â€” CORS: permitimos llamadas desde tu dominio y localhost â€”â€”â€”â€”â€”
CORS(
    app,
    resources={r"/api/*": {
        "origins": [
            "https://code-soluction.com",
            "https://www.code-soluction.com",
            "http://localhost:3000",
            "http://127.0.0.1:3000"
        ]
    }},
    supports_credentials=True
)

# â€”â€”â€”â€”â€” Inicializar Gemini â€”â€”â€”â€”â€”
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
MODEL_NAME = "models/gemini-2.0-flash"

# â€”â€”â€”â€”â€” Flujo clÃ­nico paso a paso â€”â€”â€”â€”â€”
required_fields = [
    "motivo_principal",
    "duracion_sintomas",
    "intensidad",
    "edad",
    "sexo",
    "antecedentes_medicos",
]
field_prompts = {
    "motivo_principal":
        "ðŸ‘‹ Hola, doctor/a. Â¿CuÃ¡l considera usted que es el motivo principal de consulta de este paciente?",
    "duracion_sintomas":
        "Gracias. Me dice que el motivo es â€œ{motivo_principal}â€. Â¿CuÃ¡nto tiempo lleva con esos sÃ­ntomas?",
    "intensidad":
        "Entendido. Â¿QuÃ© tan severos son esos sÃ­ntomas (leve, moderado, severo)?",
    "edad":
        "Perfecto. Â¿QuÃ© edad tiene el paciente?",
    "sexo":
        "Bien. Â¿CuÃ¡l es el sexo asignado al nacer y el gÃ©nero actual?",
    "antecedentes_medicos":
        "Â¿Antecedentes mÃ©dicos relevantes (enfermedades previas, cirugÃ­as, alergias, medicaciÃ³n)?",
}

def get_system_instruction():
    return (
        "Eres una IA mÃ©dica multimodal. "
        "Primero analiza cualquier imagen mÃ©dica que te envÃ­en. "
        "Solo despuÃ©s, recopila datos clÃ­nicos paso a paso y al final sugiere diagnÃ³sticos y recomendaciones."
    )

def build_summary(collected: dict) -> str:
    if not collected:
        return ""
    lines = [f"- **{k.replace('_',' ').capitalize()}**: {v}" for k,v in collected.items()]
    return "InformaciÃ³n recopilada hasta ahora:\n" + "\n".join(lines) + "\n\n"

# â€”â€”â€”â€”â€” Estado en memoria (desarrollo) â€”â€”â€”â€”â€”
session_data = {}

@app.route('/api/analyze-image', methods=['POST'])
def analyze_image():
    data    = request.get_json() or {}
    img_b64 = data.get('image','')
    logger.info(f"[analyze-image] Recibido base64 de longitud {len(img_b64)}")

    # Devolvemos un 200 y un JSON vÃ¡lido aunque venga vacÃ­o
    description = ""
    if img_b64:
        try:
            resp = genai.annotate_image(
                model="models/gemini-image-alpha",
                image=img_b64,
                supports=["TEXT"]
            )
            if resp and getattr(resp, "annotations", None):
                description = resp.annotations[0].text or ""
            logger.info(f"[analyze-image] DescripciÃ³n generada: {description[:80]}â€¦")
        except Exception as e:
            logger.exception("[analyze-image] Error llamando a Gemini:")
            # description queda en "" y devolvemos 200 para evitar el catch del front
    else:
        logger.warning("[analyze-image] No se proporcionÃ³ ninguna imagen.")

    return jsonify({'description': description}), 200


@app.route('/api/chat', methods=['POST'])
def chat():
    data      = request.get_json() or {}
    user_text = data.get('message','').strip()
    logger.info(f"[chat] Mensaje usuario: {user_text!r}, session: {flask_session.get('session_id')}")

    # â€” Inicializar o recuperar sesiÃ³n â€”
    sid = flask_session.get('session_id')
    if not sid or sid not in session_data:
        sid = str(uuid.uuid4())
        flask_session['session_id'] = sid
        flask_session['step']       = 0
        session_data[sid]           = {"fields": {}, "image_analyzed": False}
        logger.info(f"[chat] Nueva sesiÃ³n: {sid}")

    step  = flask_session.get('step', 0)
    state = session_data[sid]
    collected = state["fields"]

    # â€” Guardar texto clÃ­nico si estamos en esa fase â€”
    parts = []
    if user_text and step < len(required_fields):
        campo = required_fields[step]
        collected[campo] = user_text
        logger.info(f"[chat] SesiÃ³n {sid}: guardado {campo} = {user_text!r}")
        step += 1
        flask_session['step'] = step

    # â€” Preparamos el siguiente prompt â€”
    if step < len(required_fields):
        key      = required_fields[step]
        question = field_prompts[key].format(**collected)
        summary  = build_summary(collected)
        prompt_text = summary + question
    else:
        info_lines = "\n".join(f"- {k}: {v}" for k,v in collected.items())
        prompt_text = (
            "Gracias por toda la informaciÃ³n. Con estos datos, analiza en profundidad "
            "los hallazgos y sugiere diagnÃ³sticos, hipÃ³tesis y recomendaciones.\n\n"
            f"InformaciÃ³n recopilada:\n{info_lines}"
        )
        # limpiar sesiÃ³n
        session_data.pop(sid, None)
        flask_session.pop('session_id', None)
        flask_session.pop('step', None)
        logger.info(f"[chat] SesiÃ³n {sid} completada")

    full_text = f"{get_system_instruction()}\n\n{prompt_text}"
    parts.append({"text": full_text})
    logger.info(f"[chat] Prompt a Gemini: {prompt_text[:80]}â€¦")

    try:
        model = genai.GenerativeModel(MODEL_NAME)
        resp  = model.generate_content({"parts": parts})
        ai_text = getattr(resp, "text","").strip()
        logger.info(f"[chat] Respuesta IA: {ai_text[:80]}â€¦")
        return jsonify({"response": ai_text}), 200
    except Exception as e:
        logger.exception("[chat] Error en generaciÃ³n IA:")
        return jsonify({"response": "Lo siento, ha ocurrido un error interno."}), 500


if __name__ == '__main__':
    port = int(os.getenv("PORT",5000))
    app.run(host='0.0.0.0', port=port)
