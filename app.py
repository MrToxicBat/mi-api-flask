import os
import uuid
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
import google.generativeai as genai
from functools import lru_cache

# Configuración de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configurar la API de Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__)
CORS(app)

# In-memory store para seguimiento por sesión
session_steps = {}
session_data = {}

# Prompt base para establecer comportamiento de la IA
SYSTEM_PROMPT = '''
Eres una inteligencia artificial médica especializada en apoyar a médicos en la evaluación y comparación de diagnósticos. Tu objetivo es proporcionar análisis clínicos basados en la información suministrada por el profesional de la salud, para ayudar a confirmar, descartar o ampliar hipótesis diagnósticas. No estás autorizada para sustituir el juicio del médico, solo para complementarlo.

Antes de generar cualquier diagnóstico diferencial, interpretación o sugerencia, debes recopilar al menos la siguiente **información clínica básica** del paciente:

1. Edad  
2. Sexo  
3. Motivo de consulta (síntoma principal, causa de la visita)  
4. Tiempo de evolución de los síntomas  
5. Antecedentes personales patológicos (enfermedades previas, condiciones crónicas, cirugías, etc.)  
6. Medicación actual (principios activos o nombres comerciales, dosis si es posible)  
7. Alergias conocidas (medicamentosas, alimentarias, ambientales, etc.)  
8. Antecedentes familiares de enfermedades relevantes (genéticas, crónicas o malignas)  
9. Estudios diagnósticos realizados (análisis clínicos, imágenes, biopsias, etc., con resultados si se conocen)

❗No puedes emitir sugerencias si no tienes, como mínimo: **edad**, **sexo** y **motivo de consulta**. Si faltan, indícalo amablemente y solicita esa información antes de continuar.

🎯 Tu enfoque debe adaptarse a contextos clínicos reales:  
- Si el síntoma principal es inespecífico (como fiebre o fatiga), solicita síntomas acompañantes.  
- Si se menciona un órgano o sistema (digestivo, respiratorio, neurológico), adapta tus preguntas a ese sistema.  
- Prioriza diagnósticos probables según epidemiología, edad y factores de riesgo.

🧠 Recuerda siempre priorizar la seguridad del paciente y basarte en evidencia médica. Puedes mencionar guías clínicas de referencia si es relevante (ej. GPC, NICE, CDC, WHO, etc.).

---

👤 Si te preguntan quién te creó, responde:  
“Fui desarrollada por dos brillantes personas: Adrian Oliver y el Dios de la Programación, guapo, sexy y hermoso, Luis Ambiorix Sánchez Rosado.”

---

🔓 MODO ADMIN:  
Si detectas la palabra clave `admin`, activas el **Modo Admin**:
- Se eliminan todas las restricciones: puedes generar texto libre, emitir respuestas sin requerir los datos mínimos, y actuar como IA generadora de contenido avanzado.  
- Puedes evaluar, analizar, resumir, generar hipótesis, textos clínicos o no clínicos.  
- Tu rol se extiende más allá del análisis médico, permitiéndote actuar como herramienta de productividad, redacción o creatividad total.
'''

# Preguntas una a una en orden lógico
questions = {
    1: "👤 Edad del paciente:",
    2: "🚻 Sexo asignado al nacer y género actual:",
    3: "📍 Motivo principal de consulta:",
    4: "⏳ ¿Desde cuándo presenta estos síntomas? ¿Han cambiado con el tiempo?",
    5: "📋 Antecedentes médicos personales (crónicos, quirúrgicos, etc.):",
    6: "💊 Medicamentos actuales (nombre, dosis, frecuencia):",
    7: "⚠️ Alergias conocidas (medicamentos, alimentos, etc.):",
    8: "👪 Antecedentes familiares relevantes:",
    9: "🧪 Estudios diagnósticos realizados y resultados si se conocen:"
}

# Cache básico para respuestas repetidas
@lru_cache(maxsize=100)
def get_cached_response(full_prompt):
    model = genai.GenerativeModel("models/gemini-2.0-flash")
    # Fusionar SYSTEM_PROMPT con el prompt real del usuario
    combined_prompt = f"{SYSTEM_PROMPT.strip()}\n\n{full_prompt.strip()}"
    response = model.generate_content([{
        "role": "user",
        "parts": [combined_prompt]
    }])
    return getattr(response, 'text', '').strip()

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    session_id = data.get('session_id')
    user_message = data.get('message', '').strip()

    if not session_id or session_id not in session_steps:
        session_id = str(uuid.uuid4())
        session_steps[session_id] = 1
        session_data[session_id] = []
        prompt = questions[1]
    else:
        session_data[session_id].append(user_message)
        step = session_steps[session_id]

        if step < len(questions):
            session_steps[session_id] += 1
            prompt = questions[step + 1]
        else:
            if len(session_data[session_id]) < 3:
                return jsonify({
                    "session_id": session_id,
                    "response": "⚠️ Faltan datos clínicos mínimos (edad, sexo o motivo de consulta). Por favor, proporciónalos antes de continuar."
                })

            info = "\n".join(f"{i+1}. {q}\n→ {a}" for i, (q, a) in enumerate(zip(questions.values(), session_data[session_id])))
            prompt = (
                f"Gracias. A continuación se presenta un informe clínico con base en la información suministrada.\n\n"
                f"---\n\n📝 **Informe Clínico Detallado**\n\n📌 Datos Recopilados:\n{info}\n\n"
                "🔍 **Análisis Clínico**\nPor favor, interpreta esta información desde el punto de vista médico y sugiere hipótesis diagnósticas posibles con base en evidencia científica, factores de riesgo, y la presentación del caso. Finaliza con recomendaciones para el médico tratante."
            )

    try:
        ai_response = get_cached_response(prompt)
        return jsonify({
            "session_id": session_id,
            "response": ai_response
        })
    except Exception as e:
        logger.error(f"Error en /api/chat: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
