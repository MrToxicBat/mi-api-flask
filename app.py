import os
import uuid
import logging
import base64
from flask import Flask, request, jsonify, session as flask_session
from flask_cors import CORS
import google.generativeai as genai

# ‚Äî‚Äî‚Äî Configuraci√≥n b√°sica ‚Äî‚Äî‚Äî
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
app = Flask(__name__)
app.secret_key = os.getenv("SECRET_KEY", "dev_secret_key")

# CORS para tu frontend
CORS(app,
     supports_credentials=True,
     origins=[os.getenv("FRONTEND_ORIGIN", "https://code-soluction.com")])

# ‚Äî‚Äî‚Äî Inicializar Gemini ‚Äî‚Äî‚Äî
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Modelo multimodal v√°lido (detectado con /api/list-models)
MODEL_NAME = "models/gemini-2.0-flash"

# ‚Äî‚Äî‚Äî Flujo de preguntas ‚Äî‚Äî‚Äî
required_fields = [
    "motivo_principal",
    "duracion_sintomas",
    "intensidad",
    "edad",
    "sexo",
    "antecedentes_medicos",
]
field_prompts = {
    "motivo_principal":
        "üëã Hola, doctor/a. ¬øCu√°l considera usted que es el motivo principal de consulta de este paciente?",
    "duracion_sintomas":
        "Gracias. Me dice que el motivo es ‚Äú{motivo_principal}‚Äù. ¬øCu√°nto tiempo lleva con esos s√≠ntomas?",
    "intensidad":
        "Entendido. ¬øQu√© tan severos son esos s√≠ntomas (leve, moderado, severo)?",
    "edad":
        "Perfecto. ¬øQu√© edad tiene el paciente?",
    "sexo":
        "Bien. ¬øCu√°l es el sexo asignado al nacer y el g√©nero actual?",
    "antecedentes_medicos":
        "¬øAntecedentes m√©dicos relevantes (enfermedades previas, cirug√≠as, alergias, medicaci√≥n)?",
}

def get_system_instruction():
    return (
        "Eres una IA m√©dica multimodal. "
        "Recopila primero estos datos paso a paso: motivo principal, duraci√≥n de s√≠ntomas, intensidad, edad, sexo y antecedentes. "
        "Cuando est√©n completos, analiza la informaci√≥n cl√≠nica (y cualquier imagen m√©dica) y sugiere posibles diagn√≥sticos y recomendaciones."
    )

def build_summary(collected: dict) -> str:
    """Construye un bloque de texto con todo lo ya recopilado."""
    if not collected:
        return ""
    lines = [f"- **{k.replace('_',' ').capitalize()}**: {v}" for k, v in collected.items()]
    return "Informaci√≥n recopilada hasta ahora:\n" + "\n".join(lines) + "\n\n"

# Sesiones en memoria
session_data = {}

@app.route('/api/chat', methods=['POST'])
def chat():
    data       = request.json or {}
    user_text  = data.get('message', '').strip()
    image_b64  = data.get('image')       # Base64 puro
    image_type = data.get('image_type')  # e.g. "image/png"

    # ‚Äî Sesi√≥n y paso ‚Äî
    sid = flask_session.get('session_id')
    if not sid or sid not in session_data:
        sid = str(uuid.uuid4())
        flask_session['session_id'] = sid
        flask_session['step'] = 0
        session_data[sid] = {}
        logger.info(f"Nueva sesi√≥n {sid}")

    step      = flask_session['step']
    collected = session_data[sid]

    # ‚Äî Manejo de inputs e incremento de paso ‚Äî
    if image_b64 and not user_text:
        # no guardamos en collected: an√°lisis directo
        next_prompt = "Por favor, analiza esta imagen m√©dica."
        summary = ""
    else:
        # Si llega texto y a√∫n faltan campos, lo guardamos
        if user_text and step < len(required_fields):
            campo = required_fields[step]
            collected[campo] = user_text
            logger.info(f"Sesi√≥n {sid}: guardado {campo} = {user_text!r}")
            step += 1
            flask_session['step'] = step

        # Elegir siguiente prompt
        if step < len(required_fields):
            siguiente = required_fields[step]
            next_prompt = field_prompts[siguiente].format(**collected)
        else:
            # Todos los campos listos: an√°lisis final
            info_lines = "\n".join(f"- {k}: {v}" for k, v in collected.items())
            next_prompt = (
                "Gracias por toda la informaci√≥n. Con estos datos, analiza en profundidad los hallazgos "
                "y sugiere diagn√≥sticos, hip√≥tesis y recomendaciones.\n\n"
                f"Informaci√≥n recopilada:\n{info_lines}"
            )
            # Limpiar para nueva conversaci√≥n
            session_data.pop(sid, None)
            flask_session.pop('session_id', None)
            flask_session.pop('step', None)
            logger.info(f"Sesi√≥n {sid} completada")

        summary = build_summary(collected)

    # ‚Äî Construir prompt completo ‚Äî
    full_prompt = f"{get_system_instruction()}\n\n{summary}{next_prompt}"

    # ‚Äî Montar inputs multimodal ‚Äî
    inputs = []
    if image_b64 and not user_text:
        inputs.append({"image": {"data": image_b64, "mime_type": image_type}})
    inputs.append({"text": full_prompt})

    # ‚Äî Llamada a Gemini ‚Äî
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        resp  = model.generate_content(inputs)
        ai_text = getattr(resp, "text", "").strip()
        return jsonify({"response": ai_text})
    except Exception as e:
        logger.error("Error en /api/chat", exc_info=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.getenv("PORT", 5000)))
