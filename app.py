import os
import uuid
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
import google.generativeai as genai

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configurar la API de Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__)
CORS(app)

# In-memory store for tracking conversation steps per session
session_steps = {}
# Opcional: almacenar respuestas del usuario para contexto completo
session_data = {}

# Instrucci√≥n del sistema: restringir respuestas solo a medicina
def get_system_instruction():
    return (
        "Eres una IA m√©dica especializada. Solo respondes preguntas relacionadas con medicina. "
        "Para cualquier otra consulta, responde: 'Lo siento, no puedo ayudar con eso; esta IA solo responde preguntas relacionadas con medicina.'"
    )

# Preguntas interactivas predefinidas
questions = {
    1: "üñãÔ∏è **Parte 1: Datos Demogr√°ficos**\nPor favor, ind√≠came:\n1. Edad exacta\n2. Sexo asignado al nacer y g√©nero actual\n3. Ocupaci√≥n (y si existe alg√∫n riesgo relacionado con su trabajo)",
    2: "üîç **Parte 2: Antecedentes Personales y Familiares**\nPor favor, ind√≠came:\n1. Enfermedades cr√≥nicas (p.ej., hipertensi√≥n, diabetes, etc.)\n2. Cirug√≠as previas (¬øCu√°ndo y por qu√©?)\n3. Antecedentes familiares de patolog√≠as graves",  
    3: "üåÄ **Parte 3: Historia de la Enfermedad Actual**\nPor favor, detalla:\n1. Motivo de consulta principal\n2. Fecha de inicio y evoluci√≥n\n3. Caracter√≠sticas del s√≠ntoma (localizaci√≥n, intensidad, calidad)\n4. Factores que alivian o agravan",  
    4: "üîç **Parte 4: Revisi√≥n por Sistemas**\nIndica si presenta alguno de los siguientes s√≠ntomas:\n- Cardiopulmonar (fiebre, tos, disnea)\n- Hematol√≥gico (sangrados, moretones)\n- Musculoesquel√©tico (rigidez, hinchaz√≥n)\n- Gastrointestinal (n√°useas, v√≥mitos)\n- Genitourinario (dolor al orinar, cambios en la frecuencia)\n- Neurol√≥gico (cefalea, mareos)",  
    5: "üíä **Parte 5: Alergias y Medicaci√≥n Actual**\nPor favor, ind√≠came:\n1. Medicamentos en uso (nombre, dosis y frecuencia)\n2. Alergias conocidas (f√°rmacos, alimentos, l√°tex)\n3. Adherencia al tratamiento",  
    6: "üö¨ **Parte 6: Estilo de Vida y Exposici√≥n**\nDetalla:\n1. Tabaquismo (cantidad y duraci√≥n)\n2. Consumo de alcohol o drogas (cantidad y frecuencia)\n3. Exposici√≥n ocupacional/ambiental relevante",  
    7: "üìÖ **Parte 7: Detalles de la Imagen M√©dica**\nPor favor, ind√≠came:\n1. Tipo de imagen (radiograf√≠a, TAC, RM, ecograf√≠a u otra)\n2. Fecha y modalidad\n3. Proyecciones y calidad\n4. Zona de inter√©s o hallazgos observados"
}

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    session_id = data.get('session_id')
    user_message = data.get('message', '').strip()

    # Obtener instrucci√≥n del sistema
    system_instruction = get_system_instruction()

    # Iniciar nueva sesi√≥n si no existe
    if not session_id or session_id not in session_steps:
        session_id = str(uuid.uuid4())
        session_steps[session_id] = 1
        session_data[session_id] = []
        prompt = questions[1]
    else:
        # Guardar respuesta del usuario
        session_data[session_id].append(user_message)
        step = session_steps[session_id]
        # Avanzar al siguiente paso o generar an√°lisis
        if step < len(questions):
            session_steps[session_id] = step + 1
            prompt = questions[step + 1]
        else:
            # Todas las partes completadas: construir prompt de an√°lisis
            full_info = "\n".join(f"- {ans}" for ans in session_data[session_id])
            prompt = (
                "Gracias por la informaci√≥n.\nCon estos datos, analiza en profundidad las im√°genes m√©dicas proporcionadas y sugiere posibles diagn√≥sticos basados en s√≠ntomas y hallazgos.\n"
                f"Informaci√≥n recopilada:\n{full_info}\n"
                "Utiliza un formato claro, con secciones de hallazgos, hip√≥tesis diagn√≥stica y recomendaciones para el m√©dico."
            )

    # Combinar instrucci√≥n del sistema y prompt de usuario
    full_prompt = f"{system_instruction}\n\n{prompt}"

    try:
        model = genai.GenerativeModel("models/gemini-2.0-flash")
        resp = model.generate_content([{"text": full_prompt}])
        ai_response = getattr(resp, 'text', '').strip()
        return jsonify({
            "session_id": session_id,
            "response": ai_response
        })
    except Exception as e:
        logger.error(f"Error en /api/chat: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
