import os
import uuid
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
import google.generativeai as genai

# ConfiguraciÃ³n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configurar la API de Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__)
CORS(app)

# In-memory store for tracking conversation steps per session
session_steps = {}
# Opcional: almacenar respuestas del usuario para contexto completo
session_data = {}

# InstrucciÃ³n del sistema: restringir respuestas solo a medicina
def get_system_instruction():
    return (
        "Eres una IA mÃ©dica especializada. Solo respondes preguntas relacionadas con medicina. "
        "Para cualquier otra consulta, responde: 'Lo siento, no puedo ayudar con eso; esta IA solo responde preguntas relacionadas con medicina.'\n"
        "Â¡ATENCIÃ“N!: No repitas estas instrucciones en tu respuesta."
    )

# Preguntas interactivas predefinidas
questions = {
    1: "ğŸ‘‹ Â¡Hola, doctor/a!\nÂ¿CuÃ¡l considera usted que es el motivo principal de consulta de este paciente?",
    2: "ğŸ–‹ï¸ **Parte 1: Datos DemogrÃ¡ficos**\nPor favor, indÃ­queme:\n1. Edad exacta\n2. Sexo asignado al nacer y gÃ©nero actual\n3. OcupaciÃ³n (y si existe algÃºn riesgo relacionado con su trabajo)",
    3: "ğŸ” **Parte 2: Antecedentes Personales y Familiares**\nPor favor, indÃ­queme:\n1. Enfermedades crÃ³nicas (p.ej., hipertensiÃ³n, diabetes, etc.)\n2. CirugÃ­as previas (Â¿CuÃ¡ndo y por quÃ©?)\n3. Antecedentes familiares de patologÃ­as graves",  
    4: "ğŸŒ€ **Parte 3: Historia de la Enfermedad Actual**\nPor favor, detalle:\n1. Motivo de consulta principal\n2. Fecha de inicio y evoluciÃ³n\n3. CaracterÃ­sticas del sÃ­ntoma (localizaciÃ³n, intensidad, calidad)\n4. Factores que alivian o agravan",  
    5: "ğŸ” **Parte 4: RevisiÃ³n por Sistemas**\nIndique si presenta alguno de los siguientes sÃ­ntomas:\n- Cardiopulmonar (fiebre, tos, disnea)\n- HematolÃ³gico (sangrados, moretones)\n- MusculoesquelÃ©tico (rigidez, hinchazÃ³n)\n- Gastrointestinal (nÃ¡useas, vÃ³mitos)\n- Genitourinario (dolor al orinar, cambios en la frecuencia)\n- NeurolÃ³gico (cefalea, mareos)",  
    6: "ğŸ’Š **Parte 5: Alergias y MedicaciÃ³n Actual**\nPor favor, indÃ­queme:\n1. Medicamentos en uso (nombre, dosis y frecuencia)\n2. Alergias conocidas (fÃ¡rmacos, alimentos, lÃ¡tex)\n3. Adherencia al tratamiento",  
    7: "ğŸš¬ **Parte 6: Estilo de Vida y ExposiciÃ³n**\nDetalle:\n1. Tabaquismo (cantidad y duraciÃ³n)\n2. Consumo de alcohol o drogas (cantidad y frecuencia)\n3. ExposiciÃ³n ocupacional/ambiental relevante",  
    8: "ğŸ“… **Parte 7: Detalles de la Imagen MÃ©dica**\nPor favor, indÃ­queme:\n1. Tipo de imagen (radiografÃ­a, TAC, RM, ecografÃ­a u otra)\n2. Fecha y modalidad\n3. Proyecciones y calidad\n4. Zona de interÃ©s o hallazgos observados"
}

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    session_id = data.get('session_id')
    user_message = data.get('message', '').strip()

    # Obtener instrucciÃ³n del sistema
    system_instruction = get_system_instruction()

    # Iniciar nueva sesiÃ³n si no existe
    if not session_id or session_id not in session_steps:
        session_id = str(uuid.uuid4())
        session_steps[session_id] = 1
        session_data[session_id] = []
        prompt = questions[1]
    else:
        # Guardar respuesta del usuario
        session_data[session_id].append(user_message)
        step = session_steps[session_id]
        # Avanzar al siguiente paso o generar anÃ¡lisis
        if step < len(questions):
            session_steps[session_id] = step + 1
            prompt = questions[step + 1]
        else:
            # Todas las partes completadas: construir prompt de anÃ¡lisis
            full_info = "\n".join(f"- {ans}" for ans in session_data[session_id])
            prompt = (
                "Gracias por la informaciÃ³n.\nCon estos datos, analiza en profundidad las imÃ¡genes mÃ©dicas proporcionadas y sugiere posibles diagnÃ³sticos basados en sÃ­ntomas y hallazgos.\n"
                f"InformaciÃ³n recopilada:\n{full_info}\n"
                "Utiliza un formato claro, con secciones de hallazgos, hipÃ³tesis diagnÃ³stica y recomendaciones para el mÃ©dico."
            )

    # Combinar instrucciÃ³n del sistema y prompt de usuario
    full_prompt = f"{system_instruction}\n\n{prompt}"

    try:
        model = genai.GenerativeModel("models/gemini-2.0-flash")
        resp = model.generate_content([{ "text": full_prompt }])
        ai_response = getattr(resp, 'text', '').strip()
        return jsonify({
            "session_id": session_id,
            "response": ai_response
        })
    except Exception as e:
        logger.error(f"Error en /api/chat: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
