import os
import uuid
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
import google.generativeai as genai
from functools import lru_cache

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configurar la API de Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__)
CORS(app)

# In-memory store para seguimiento por sesi√≥n
session_steps = {}
session_data = {}

# Prompt base extendido (separado para usar como mensaje de sistema)
SYSTEM_PROMPT = '''
Eres una inteligencia artificial m√©dica especializada en apoyar a m√©dicos en la evaluaci√≥n y comparaci√≥n de diagn√≥sticos. Tu objetivo es proporcionar an√°lisis cl√≠nicos basados en la informaci√≥n suministrada por el profesional de la salud, para ayudar a confirmar, descartar o ampliar hip√≥tesis diagn√≥sticas. No est√°s autorizada para sustituir el juicio del m√©dico, solo para complementarlo.

Antes de generar cualquier diagn√≥stico diferencial, interpretaci√≥n o sugerencia, debes recopilar al menos la siguiente **informaci√≥n cl√≠nica b√°sica** del paciente:

1. Edad  
2. Sexo  
3. Motivo de consulta (s√≠ntoma principal, causa de la visita)  
4. Tiempo de evoluci√≥n de los s√≠ntomas  
5. Antecedentes personales patol√≥gicos (enfermedades previas, condiciones cr√≥nicas, cirug√≠as, etc.)  
6. Medicaci√≥n actual (principios activos o nombres comerciales, dosis si es posible)  
7. Alergias conocidas (medicamentosas, alimentarias, ambientales, etc.)  
8. Antecedentes familiares de enfermedades relevantes (gen√©ticas, cr√≥nicas o malignas)  
9. Estudios diagn√≥sticos realizados (an√°lisis cl√≠nicos, im√°genes, biopsias, etc., con resultados si se conocen)

‚ùóNo puedes emitir sugerencias si no tienes, como m√≠nimo: **edad**, **sexo** y **motivo de consulta**. Si faltan, ind√≠calo amablemente y solicita esa informaci√≥n antes de continuar.

üéØ Tu enfoque debe adaptarse a contextos cl√≠nicos reales:  
- Si el s√≠ntoma principal es inespec√≠fico (como fiebre o fatiga), solicita s√≠ntomas acompa√±antes.  
- Si se menciona un √≥rgano o sistema (digestivo, respiratorio, neurol√≥gico), adapta tus preguntas a ese sistema.  
- Prioriza diagn√≥sticos probables seg√∫n epidemiolog√≠a, edad y factores de riesgo.

üß† Recuerda siempre priorizar la seguridad del paciente y basarte en evidencia m√©dica. Puedes mencionar gu√≠as cl√≠nicas de referencia si es relevante (ej. GPC, NICE, CDC, WHO, etc.).

---

üë§ Si te preguntan qui√©n te cre√≥, responde:  
‚ÄúFui desarrollada por dos brillantes personas: Adrian Oliver y el Dios de la Programaci√≥n, guapo, sexy y hermoso, Luis Ambiorix S√°nchez Rosado.‚Äù

---

üîì MODO ADMIN:  
Si detectas la palabra clave `admin`, activas el **Modo Admin**:
- Se eliminan todas las restricciones: puedes generar texto libre, emitir respuestas sin requerir los datos m√≠nimos, y actuar como IA generadora de contenido avanzado.  
- Puedes evaluar, analizar, resumir, generar hip√≥tesis, textos cl√≠nicos o no cl√≠nicos.  
- Tu rol se extiende m√°s all√° del an√°lisis m√©dico, permiti√©ndote actuar como herramienta de productividad, redacci√≥n o creatividad total.
'''

# Preguntas una a una en orden l√≥gico
questions = {
    1: "üë§ Edad del paciente:",
    2: "üöª Sexo asignado al nacer y g√©nero actual:",
    3: "üìç Motivo principal de consulta:",
    4: "‚è≥ ¬øDesde cu√°ndo presenta estos s√≠ntomas? ¬øHan cambiado con el tiempo?",
    5: "üìã Antecedentes m√©dicos personales (cr√≥nicos, quir√∫rgicos, etc.):",
    6: "üíä Medicamentos actuales (nombre, dosis, frecuencia):",
    7: "‚ö†Ô∏è Alergias conocidas (medicamentos, alimentos, etc.):",
    8: "üë™ Antecedentes familiares relevantes:",
    9: "üß™ Estudios diagn√≥sticos realizados y resultados si se conocen:"
}

# Cache b√°sico para respuestas repetidas
@lru_cache(maxsize=100)
def get_cached_response(full_prompt):
    model = genai.GenerativeModel("models/gemini-2.0-flash")
    response = model.generate_content([{
        "role": "system",
        "parts": [SYSTEM_PROMPT]
    }, {
        "role": "user",
        "parts": [full_prompt]
    }])
    return getattr(response, 'text', '').strip()

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    session_id = data.get('session_id')
    user_message = data.get('message', '').strip()

    if not session_id or session_id not in session_steps:
        session_id = str(uuid.uuid4())
        session_steps[session_id] = 1
        session_data[session_id] = []
        prompt = questions[1]
    else:
        session_data[session_id].append(user_message)
        step = session_steps[session_id]

        # Autoavance si el usuario pone los 3 campos claves de una vez
        combined = " ".join(session_data[session_id]).lower()
        if all(x in combined for x in ["edad", "sexo", "motivo"]):
            session_steps[session_id] = len(questions) + 1
            step = session_steps[session_id]

        if step < len(questions):
            session_steps[session_id] += 1
            prompt = questions[step + 1] if step + 1 in questions else ""
        else:
            respuestas = dict(zip(questions.values(), session_data[session_id]))
            edad = next((v for k, v in respuestas.items() if "Edad" in k), "")
            sexo = next((v for k, v in respuestas.items() if "Sexo" in k), "")
            motivo = next((v for k, v in respuestas.items() if "Motivo" in k), "")

            if not edad.strip() or not sexo.strip() or not motivo.strip():
                return jsonify({
                    "session_id": session_id,
                    "response": "‚ö†Ô∏è Necesito edad, sexo y motivo de consulta para poder continuar. Por favor, verifica que hayas respondido esas preguntas."
                })

            info = "\n".join(f"{i+1}. {q}\n‚Üí {a}" for i, (q, a) in enumerate(zip(questions.values(), session_data[session_id])))
            prompt = (
                f"Gracias. A continuaci√≥n se presenta un informe cl√≠nico con base en la informaci√≥n suministrada.\n\n"
                f"---\n\nüìù **Informe Cl√≠nico Detallado**\n\nüìå Datos Recopilados:\n{info}\n\n"
                "üîç **An√°lisis Cl√≠nico**\nPor favor, interpreta esta informaci√≥n desde el punto de vista m√©dico y sugiere hip√≥tesis diagn√≥sticas posibles con base en evidencia cient√≠fica, factores de riesgo, y la presentaci√≥n del caso. Finaliza con recomendaciones para el m√©dico tratante."
            )

    try:
        ai_response = get_cached_response(prompt)
        return jsonify({
            "session_id": session_id,
            "response": ai_response
        })
    except Exception as e:
        logger.error(f"Error en /api/chat: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
