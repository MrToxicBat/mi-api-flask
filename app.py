import os
import uuid
import logging
import base64
from flask import Flask, request, jsonify, session as flask_session
from flask_cors import CORS
import google.generativeai as genai

# â€”â€”â€” ConfiguraciÃ³n bÃ¡sica â€”â€”â€”
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.secret_key = os.getenv("SECRET_KEY", "dev_secret_key")

# CORS abierto para depuraciÃ³n; luego restringe a tu dominio:
CORS(app, supports_credentials=True, origins=[os.getenv("FRONTEND_ORIGIN", "*")])

# â€”â€”â€” Inicializar Gemini â€”â€”â€”
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# â€”â€”â€” Detectar dinÃ¡micamente un modelo multimodal vÃ¡lido â€”â€”â€”
MODEL_NAME = None
try:
    models = genai.list_models().models
    for m in models:
        if "generateContent" in m.supported_methods:
            MODEL_NAME = m.name
            logger.info(f"Usando modelo multimodal: {MODEL_NAME}")
            break
    if MODEL_NAME is None:
        raise RuntimeError("NingÃºn modelo soporta generateContent")
except Exception as e:
    logger.error("No pude listar modelos o encontrar uno multimodal:", exc_info=True)
    # Fallback a un modelo de texto, si lo prefieres:
    MODEL_NAME = "models/gemini-2.0-preview"
    logger.info(f"Usando fallback de modelo: {MODEL_NAME}")

# â€”â€”â€” Campos a recopilar â€”â€”â€”
required_fields = [
    "motivo_principal",
    "duracion_sintomas",
    "intensidad",
    "edad",
    "sexo",
    "antecedentes_medicos",
]

field_prompts = {
    "motivo_principal":
        "ðŸ‘‹ Hola, doctor/a. Â¿CuÃ¡l es el motivo principal de consulta de este paciente?",
    "duracion_sintomas":
        "Gracias. Me dice que es Â«{motivo_principal}Â». Â¿CuÃ¡nto tiempo lleva con esos sÃ­ntomas?",
    "intensidad":
        "Entendido. Â¿QuÃ© tan severos son (leve, moderado, severo)?",
    "edad":
        "Perfecto. Â¿QuÃ© edad tiene el paciente?",
    "sexo":
        "Bien. Â¿Sexo asignado al nacer y gÃ©nero actual?",
    "antecedentes_medicos":
        "Â¿Antecedentes mÃ©dicos relevantes (enfermedades previas, cirugÃ­as, alergias, medicaciÃ³n)?",
}

def get_system_instruction():
    return (
        "Eres una IA mÃ©dica multimodal. Puedes procesar texto e imÃ¡genes mÃ©dicas para anÃ¡lisis. "
        "Solo respondes diagnÃ³sticos y recomendaciones basadas en datos clÃ­nicos e imÃ¡genes. "
        "Si recibes otra cosa, di: 'Lo siento, solo proceso informaciÃ³n mÃ©dica.'"
    )

# â€”â€”â€” AlmacÃ©n en memoria para las sesiones â€”â€”â€”
session_data = {}

# â€”â€”â€” Endpoint opcional para inspeccionar modelos â€”â€”â€”
@app.route('/api/list-models', methods=['GET'])
def list_models():
    ms = genai.list_models().models
    return jsonify({m.name: m.supported_methods for m in ms})

# â€”â€”â€” Endpoint principal de chat â€”â€”â€”
@app.route('/api/chat', methods=['POST'])
def chat():
    logger.info("â†’ Llega /api/chat")
    data       = request.json or {}
    user_text  = data.get('message', '').strip()
    image_b64  = data.get('image')       # Base64 puro (sin prefijo data:)
    image_type = data.get('image_type')  # e.g. "image/png"

    # â€” SesiÃ³n y paso actual â€”
    sid = flask_session.get('session_id')
    if not sid or sid not in session_data:
        sid = str(uuid.uuid4())
        flask_session['session_id'] = sid
        flask_session['step'] = 0
        session_data[sid] = {}
        logger.info(f"Nueva sesiÃ³n {sid}")

    step = flask_session.get('step', 0)
    collected = session_data[sid]

    # â€” Montar lista de inputs para generate_content â€”
    inputs = []

    # Caso: imagen sin texto â†’ anÃ¡lisis inmediato
    if image_b64 and not user_text:
        inputs.append({"image": {"data": image_b64, "mime_type": image_type}})
        inputs.append({"text": "Por favor, analiza esta imagen mÃ©dica."})

    else:
        # Texto + recolecciÃ³n de campos
        if user_text and step < len(required_fields):
            campo = required_fields[step]
            collected[campo] = user_text
            logger.info(f"SesiÃ³n {sid}: guardado {campo} = {user_text!r}")
            step += 1
            flask_session['step'] = step

        if step < len(required_fields):
            siguiente = required_fields[step]
            prompt = field_prompts[siguiente].format(**collected)
            inputs.append({"text": get_system_instruction()})
            inputs.append({"text": prompt})
        else:
            # Todos los campos recogidos â†’ anÃ¡lisis final
            info_lines = "\n".join(f"- {k}: {v}" for k, v in collected.items())
            final_prompt = (
                "Gracias por la informaciÃ³n. Con estos datos, analiza en profundidad los hallazgos "
                "y sugiere posibles diagnÃ³sticos, hipÃ³tesis y recomendaciones.\n\n"
                f"InformaciÃ³n del paciente:\n{info_lines}"
            )
            inputs.append({"text": get_system_instruction()})
            inputs.append({"text": final_prompt})

            # Limpiar sesiÃ³n
            session_data.pop(sid, None)
            flask_session.pop('session_id', None)
            flask_session.pop('step', None)
            logger.info(f"SesiÃ³n {sid} completada")

    # â€” Invocar al modelo â€”
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        logger.info(f"Usando modelo {MODEL_NAME} con inputs: {inputs}")
        resp = model.generate_content(inputs)
        ai_text = getattr(resp, "text", "").strip()
        logger.info(f"Respuesta IA: {ai_text!r}")
        return jsonify({"response": ai_text})
    except Exception as e:
        logger.error("Error en /api/chat", exc_info=True)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.getenv("PORT", 5000)))
